{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39165987",
   "metadata": {},
   "source": [
    "# åˆ†å±‚å»ºæ¨¡ï¼šåœ°éœ‡è­¦æŠ¥çº§åˆ«é¢„æµ‹\n",
    "\n",
    "æœ¬ Notebook é‡‡ç”¨åˆ†å±‚å»ºæ¨¡ï¼ˆHierarchical Modelingï¼‰ç­–ç•¥æ¥è§£å†³å››åˆ†ç±»é—®é¢˜ã€‚çµæ„Ÿæ¥æºäºå¯¹ç‰¹å¾ä¸æ ‡ç­¾å…³ç³»çš„æ·±å…¥åˆ†æï¼Œç‰¹åˆ«æ˜¯ `depth` ç‰¹å¾åœ¨åŒºåˆ† `label 0` æ—¶çš„ç‹¬ç‰¹æ€§ã€‚\n",
    "\n",
    "**åˆ†ææµç¨‹:**\n",
    "1.  **ç¬¬ä¸€é˜¶æ®µï¼šåˆ†ç¦» `label 0`**\n",
    "    *   **ç›®æ ‡**: è®­ç»ƒä¸€ä¸ªç®€å•çš„äºŒå…ƒåˆ†ç±»å™¨ï¼Œç²¾ç¡®åœ°è¯†åˆ«å‡º `label 0`ã€‚\n",
    "    *   **æ•°æ®**: ä½¿ç”¨ **åŸå§‹ç‰¹å¾**ï¼Œä¸åšä»»ä½•å¤æ‚å¤„ç†ï¼Œä»¥åˆ©ç”¨ `depth` ç­‰ç‰¹å¾çš„åŸå§‹åˆ†å¸ƒä¿¡æ¯ã€‚\n",
    "    *   **æ¨¡å‹**: ä½¿ç”¨é€»è¾‘å›å½’ï¼ˆLogistic Regressionï¼‰ï¼Œå› ä¸ºå®ƒé€Ÿåº¦å¿«ä¸”æ•ˆæœå¥½ã€‚\n",
    "\n",
    "2.  **ç¬¬äºŒé˜¶æ®µï¼šåŒºåˆ† `label 1, 2, 3`**\n",
    "    *   **ç›®æ ‡**: åœ¨æ’é™¤äº† `label 0` çš„æ•°æ®é›†ä¸Šï¼Œè®­ç»ƒä¸€ä¸ªæ›´å¼ºå¤§çš„å¤šåˆ†ç±»æ¨¡å‹ã€‚\n",
    "    *   **æ•°æ®**: å¯¹å‰©ä½™æ•°æ®è¿›è¡Œå®Œæ•´çš„ **é¢„å¤„ç†ã€ç‰¹å¾å·¥ç¨‹å’ŒSMOTE**ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹å¯¹ `label 1, 2, 3` ä¹‹é—´ç»†å¾®å·®åˆ«çš„æ•æ‰èƒ½åŠ›ã€‚\n",
    "    *   **æ¨¡å‹**: ä½¿ç”¨éšæœºæ£®æ—ï¼ˆRandomForestClassifierï¼‰ã€‚\n",
    "\n",
    "3.  **åˆå¹¶é¢„æµ‹ä¸ç”Ÿæˆæäº¤æ–‡ä»¶**\n",
    "    *   å°†ä¸¤ä¸ªé˜¶æ®µçš„é¢„æµ‹ç»“æœåˆå¹¶ï¼Œç”Ÿæˆæœ€ç»ˆçš„æäº¤æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de142fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥æ‰€æœ‰éœ€è¦çš„åº“\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# æ¨¡å‹ä¸è¯„ä¼°\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# ä¸å¹³è¡¡å¤„ç†\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd35d403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully!\n",
      "Training data shape: (909, 7)\n",
      "Test data shape: (391, 6)\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"âœ… Data loaded successfully!\")\n",
    "print(\"Training data shape:\", df_train.shape)\n",
    "print(\"Test data shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93ce50",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨åŸå§‹æ•°æ®åˆ†ç¦» `label 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c03e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Stage 1: Isolating Label 0\n",
      "\n",
      "Class distribution for Stage 1:\n",
      "label\n",
      "0    674\n",
      "1    235\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Stage 1 Model CV Macro-F1 Score: 0.8524 (+/- 0.1080)\n",
      "\n",
      "âœ… Stage 1 model trained successfully!\n",
      "\n",
      "Feature coefficients for identifying Label 0:\n",
      "           Coefficient\n",
      "sig          -0.001651\n",
      "depth        -0.001699\n",
      "magnitude    -0.354804\n",
      "cdi          -0.480340\n",
      "mmi          -1.710632\n",
      "-> æ­£å¦‚EDAæ‰€æ–™, 'depth' æ˜¯åŒºåˆ† label 0 çš„æœ€é‡è¦æ­£å‘ç‰¹å¾ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ Starting Stage 1: Isolating Label 0\")\n",
    "\n",
    "# 1. å‡†å¤‡æ•°æ® (ä½¿ç”¨åŸå§‹ç‰¹å¾)\n",
    "features_raw = ['magnitude', 'depth', 'cdi', 'mmi', 'sig']\n",
    "X_stage1 = df_train[features_raw]\n",
    "y_stage1 = (df_train['label'] == 0).astype(int) # 1 if label is 0, else 0\n",
    "\n",
    "print(\"\\nClass distribution for Stage 1:\")\n",
    "print(y_stage1.value_counts())\n",
    "\n",
    "# 2. é€‰æ‹©å¹¶è®­ç»ƒæ¨¡å‹ (éšæœºæ£®æ—)\n",
    "# éšæœºæ£®æ—åŒæ ·æ”¯æŒ class_weight='balanced' æ¥å¤„ç†ç±»åˆ«ä¸å¹³è¡¡\n",
    "stage1_model = RandomForestClassifier(\n",
    "    n_estimators=500,          # å¢åŠ æ ‘çš„æ•°é‡ä»¥æé«˜ç¨³å®šæ€§\n",
    "    max_depth=10,              # é™åˆ¶æ·±åº¦ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1                  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ\n",
    ")\n",
    "\n",
    "# 3. äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½\n",
    "cv_scores = cross_val_score(stage1_model, X_stage1, y_stage1, cv=10, scoring='f1_macro')\n",
    "print(f\"\\nStage 1 Model (RandomForest) CV Macro-F1 Score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "\n",
    "# 4. åœ¨å…¨éƒ¨è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒæœ€ç»ˆçš„ç¬¬ä¸€é˜¶æ®µæ¨¡å‹\n",
    "stage1_model.fit(X_stage1, y_stage1)\n",
    "print(\"\\nâœ… Stage 1 model trained successfully!\")\n",
    "\n",
    "# æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§ (éšæœºæ£®æ—çš„ Gini importance)\n",
    "# Feature importances show the contribution of each feature to the model's decisions\n",
    "importance_df = pd.DataFrame(stage1_model.feature_importances_, index=features_raw, columns=['Importance'])\n",
    "print(\"\\nFeature importances for identifying Label 0:\")\n",
    "print(importance_df.sort_values('Importance', ascending=False))\n",
    "print(\"-> æ­£å¦‚EDAæ‰€æ–™, 'depth' æ˜¯åŒºåˆ† label 0 çš„æœ€é‡è¦ç‰¹å¾ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54643dea",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒé˜¶æ®µï¼šå¤„ç†æ•°æ®å¹¶åŒºåˆ† `label 1, 2, 3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772321cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ Starting Stage 2: Classifying Labels 1, 2, and 3\")\n",
    "\n",
    "# 1. åˆ›å»ºç¬¬äºŒé˜¶æ®µçš„æ•°æ®é›†\n",
    "df_stage2_train = df_train[df_train['label'] != 0].copy()\n",
    "print(f\"Number of samples for Stage 2: {len(df_stage2_train)}\")\n",
    "print(\"Class distribution for Stage 2:\")\n",
    "print(df_stage2_train['label'].value_counts())\n",
    "\n",
    "# 2. åº”ç”¨å®Œæ•´çš„é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹æµç¨‹\n",
    "# a. Winsorize ç¼©å°¾å¤„ç†\n",
    "feature_cols = ['magnitude', 'depth', 'cdi', 'mmi', 'sig']\n",
    "for col in feature_cols:\n",
    "    df_stage2_train[col] = winsorize(df_stage2_train[col], limits=[0.01, 0.05])\n",
    "\n",
    "# b. å¯¹ depth è¿›è¡Œå¯¹æ•°å˜æ¢\n",
    "df_stage2_train['depth'] = np.log1p(df_stage2_train['depth'])\n",
    "\n",
    "# c. æ ‡å‡†åŒ–\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['magnitude', 'depth', 'cdi', 'mmi', 'sig']\n",
    "df_stage2_train[numerical_features] = scaler.fit_transform(df_stage2_train[numerical_features])\n",
    "\n",
    "# d. åˆ›å»ºæ–°ç‰¹å¾\n",
    "df_stage2_train['cdi_mmi_interaction'] = df_stage2_train['cdi'] * df_stage2_train['mmi']\n",
    "df_stage2_train['cdi_sq'] = df_stage2_train['cdi']**2\n",
    "df_stage2_train['mmi_sq'] = df_stage2_train['mmi']**2\n",
    "\n",
    "print(\"\\nâœ… Preprocessing and feature engineering complete for Stage 2 data.\")\n",
    "\n",
    "# 3. å‡†å¤‡è®­ç»ƒæ•°æ® X å’Œ y\n",
    "X_stage2 = df_stage2_train.drop(columns=[\"id\", \"label\"]).values\n",
    "y_stage2 = df_stage2_train[\"label\"].values\n",
    "\n",
    "# 4. ä½¿ç”¨ SMOTE å¤„ç†ç±»åˆ«ä¸å¹³è¡¡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_stage2_resampled, y_stage2_resampled = smote.fit_resample(X_stage2, y_stage2)\n",
    "print(\"\\nResampled dataset shape for Stage 2: %s\" % pd.Series(y_stage2_resampled).value_counts().to_dict())\n",
    "\n",
    "# 5. è®­ç»ƒç¬¬äºŒé˜¶æ®µæ¨¡å‹ (éšæœºæ£®æ—)\n",
    "# ä½¿ç”¨åœ¨å¦ä¸€ä¸ªnotebookä¸­æ‰¾åˆ°çš„æœ€ä½³å‚æ•°ä½œä¸ºèµ·ç‚¹\n",
    "best_params_rf = {\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'class_weight': 'balanced',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "stage2_model = RandomForestClassifier(**best_params_rf)\n",
    "stage2_model.fit(X_stage2_resampled, y_stage2_resampled)\n",
    "\n",
    "print(\"\\nâœ… Stage 2 model (RandomForest) trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620809ec",
   "metadata": {},
   "source": [
    "## åˆå¹¶é¢„æµ‹å¹¶ç”Ÿæˆæäº¤æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dee1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ Generating final predictions by combining Stage 1 and Stage 2 models.\")\n",
    "\n",
    "# 1. å¯¹æµ‹è¯•é›†è¿›è¡Œç¬¬ä¸€é˜¶æ®µé¢„æµ‹\n",
    "X_test_stage1 = df_test[features_raw]\n",
    "test_pred_stage1 = stage1_model.predict(X_test_stage1) # é¢„æµ‹æ˜¯å¦ä¸º label 0\n",
    "\n",
    "# 2. åˆå§‹åŒ–æœ€ç»ˆé¢„æµ‹ç»“æœ\n",
    "final_predictions = np.zeros(len(df_test), dtype=int)\n",
    "\n",
    "# 3. å°†ç¬¬ä¸€é˜¶æ®µé¢„æµ‹ä¸º label 0 çš„æ ·æœ¬ç›´æ¥èµ‹å€¼\n",
    "label_0_indices = np.where(test_pred_stage1 == 1)[0]\n",
    "final_predictions[label_0_indices] = 0\n",
    "print(f\"Found {len(label_0_indices)} samples predicted as Label 0 in test set.\")\n",
    "\n",
    "# 4. å¯¹ç¬¬ä¸€é˜¶æ®µé¢„æµ‹ä¸ºé label 0 çš„æ ·æœ¬ï¼Œè¿›è¡Œç¬¬äºŒé˜¶æ®µé¢„æµ‹\n",
    "non_label_0_indices = np.where(test_pred_stage1 == 0)[0]\n",
    "print(f\"Found {len(non_label_0_indices)} samples to be classified by Stage 2 model.\")\n",
    "\n",
    "if len(non_label_0_indices) > 0:\n",
    "    # a. å‡†å¤‡è¿™äº›æ ·æœ¬çš„æ•°æ®\n",
    "    df_test_stage2 = df_test.iloc[non_label_0_indices].copy()\n",
    "    \n",
    "    # b. åº”ç”¨ä¸è®­ç»ƒæ—¶å®Œå…¨ç›¸åŒçš„é¢„å¤„ç†æµç¨‹\n",
    "    for col in feature_cols:\n",
    "        df_test_stage2[col] = winsorize(df_test_stage2[col], limits=[0.01, 0.05])\n",
    "    \n",
    "    df_test_stage2['depth'] = np.log1p(df_test_stage2['depth'])\n",
    "    \n",
    "    # ä½¿ç”¨åœ¨ç¬¬äºŒé˜¶æ®µè®­ç»ƒæ•°æ®ä¸Š fit å¥½çš„ scaler\n",
    "    df_test_stage2[numerical_features] = scaler.transform(df_test_stage2[numerical_features])\n",
    "    \n",
    "    df_test_stage2['cdi_mmi_interaction'] = df_test_stage2['cdi'] * df_test_stage2['mmi']\n",
    "    df_test_stage2['cdi_sq'] = df_test_stage2['cdi']**2\n",
    "    df_test_stage2['mmi_sq'] = df_test_stage2['mmi']**2\n",
    "    \n",
    "    X_test_stage2 = df_test_stage2.drop(columns=[\"id\"]).values\n",
    "    \n",
    "    # c. ä½¿ç”¨ç¬¬äºŒé˜¶æ®µæ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "    test_pred_stage2 = stage2_model.predict(X_test_stage2)\n",
    "    \n",
    "    # d. å°†é¢„æµ‹ç»“æœå¡«å……åˆ°æœ€ç»ˆé¢„æµ‹æ•°ç»„ä¸­\n",
    "    final_predictions[non_label_0_indices] = test_pred_stage2\n",
    "\n",
    "# 5. åˆ›å»ºæäº¤æ–‡ä»¶\n",
    "submission_hierarchical = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    \"label\": final_predictions\n",
    "})\n",
    "submission_hierarchical.to_csv(\"submission_hierarchical.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Hierarchical model predictions complete. Results saved to submission_hierarchical.csv\")\n",
    "print(\"\\nSubmission file head:\")\n",
    "print(submission_hierarchical.head())\n",
    "print(\"\\nFinal prediction distribution:\")\n",
    "print(submission_hierarchical['label'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
